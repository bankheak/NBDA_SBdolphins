# install devtools if not already
devtools::install_github("michaelchimento/STbayes")
# load packages
if(!require(devtools)){install.packages('devtools'); library(devtools)} # To load NBDA
# install devtools if not already
devtools::install_github("michaelchimento/STbayes")
# load packages
if(!require(devtools)){install.packages('devtools'); library(devtools)} # To load NBDA
# install devtools if not already
devtools::install_github("michaelchimento/STbayes")
# load packages
if(!require(devtools)){install.packages('devtools'); library(devtools)} # To load NBDA
# install devtools if not already
devtools::install_github("michaelchimento/STbayes")
## Bayesian
if(!require(abind)){install.packages('abind'); library(abind)} # array
if(!require(STbayes)){install.packages('STbayes'); library(STbayes)}
# install devtools if not already
devtools::install_github("michaelchimento/STbayes")
install.packages('cmdstanr')
# load packages
if(!require(devtools)){install.packages('devtools'); library(devtools)} # To load NBDA
# install devtools if not already
devtools::install_github("michaelchimento/STbayes")
install.packages("cmdstanr", repos = c("https://mc-stan.org/r-packages/", getOption("repos")))
library(cmdstanr)
install_cmdstan()
cmdstanr::check_cmdstan_toolchain(fix = TRUE)
pkgbuild::has_build_tools(debug = TRUE)
# install devtools if not already
devtools::install_github("michaelchimento/STbayes")
## Bayesian
if(!require(abind)){install.packages('abind'); library(abind)} # array
if(!require(STbayes)){install.packages('STbayes'); library(STbayes)}
?aggregate
# load packages
if(!require(devtools)){install.packages('devtools'); library(devtools)} # To load NBDA
# Install NBDA package
devtools::install_github("whoppitt/NBDA")
# install devtools if not already
devtools::install_github("michaelchimento/STbayes")
if(!require(STbayes)){install.packages('STbayes'); library(STbayes)}
if(!require(STbayes)){install.packages('STbayes'); library(STbayes)}
# install devtools if not already
devtools::install_github("michaelchimento/STbayes")
# install devtools if not already
devtools::install_github("michaelchimento/STbayes")
# Install NBDA package
devtools::install_github("whoppitt/NBDA")
# Install NBDA package
devtools::install_github("whoppitt/NBDA")
# Install NBDA package
devtools::install_github("whoppitt/NBDA", force = T)
# install devtools if not already
devtools::install_github("michaelchimento/STbayes")
if(!require(cmdstanr)){install.packages('cmdstanr'); library(cmdstanr)} # array
if(!require(remotes)){install.packages('remotes'); library(remotes)} # array
remotes::install_github("stan-dev/cmdstanr")
# install devtools if not already
devtools::install_github("michaelchimento/STbayes")
# Read in all network data
nxn <- readRDS("nxn.RData")
setwd("C:/Users/Owner/NBDA_SBdolphins/Code")
# Read in all network data
nxn <- readRDS("nxn.RData")
# Set relative path working directory
setwd("../Data") # set working directory
# Read in all network data
nxn <- readRDS("nxn.RData")
ecol_all <- as.array(readRDS("ecol_all.RData"))
# Get all unique IDs across all matrices
total_ids <- unique(unlist(lapply(nxn, rownames)))
# Update each matrix to include all IDs, filling missing rows/columns with zeros
nxn_1 <- lapply(nxn, function(mat) {
# Current IDs in this matrix
current_ids <- rownames(mat)
# Create a full zero matrix with all IDs
full_mat <- matrix(0, nrow = length(total_ids), ncol = length(total_ids),
dimnames = list(total_ids, total_ids))
# Fill in existing values
full_mat[current_ids, current_ids] <- mat
return(full_mat)
})
# Subset nxn and ecol
nxn_1 <- nxn_1[3:22]
ecol_all <- ecol_all[3:22]
# Get rid of IDs without data in nxn from ecol data
for (i in seq_along(ecol_all)) {
# Get the row/column names from the nxn matrix
target_names <- rownames(ecol_all[[i]])
# Subset the SRI matrix to match those names
nxn_1[[i]] <- nxn_1[[i]][target_names, target_names, drop = FALSE]
}
# Get all unique IDs across all matrices
total_ids <- unique(unlist(lapply(nxn_1, rownames)))
# Update each matrix to include all IDs, filling missing rows/columns with zeros
nxn_full <- lapply(nxn_1, function(mat) {
# Current IDs in this matrix
current_ids <- rownames(mat)
# Create a full zero matrix with all IDs
full_mat <- matrix(0, nrow = length(total_ids), ncol = length(total_ids),
dimnames = list(total_ids, total_ids))
# Fill in existing values
full_mat[current_ids, current_ids] <- mat
return(full_mat)
})
# Put matrices into data frame
edge_list <- do.call(rbind, lapply(seq_along(nxn_full), function(t) {
mat <- nxn_full[[t]]
ids <- colnames(mat)  # or rownames(mat), assuming square
upper_idx <- which(upper.tri(mat, diag = TRUE), arr.ind = TRUE)
data.frame(
focal = ids[upper_idx[, 1]],
other = ids[upper_idx[, 2]],
trial = 1,
assoc = mat[upper_idx],
time = t
)
}))
# Read in full data
ILV_all <- read.csv("ILV_dem.csv", header=TRUE, sep=",")
ILV_all <- ILV_all[, c("Alias", "HI_Indiv", "Mom", "Sex", "BirthYear")]
# Subset event data to include only edge_list ids
ILV_all <- subset(ILV_all, Alias %in% unique(edge_list$focal))
# Add order of acquisition data
# Create demonstrator column
filtered_data <- read.csv("filtered_data.csv")
filtered_data <- subset(filtered_data, Year %in% 1995:2014)
# Find the first year globally where Confirmed_HI == 1
first_year <- min(filtered_data$Year[filtered_data$Confirmed_HI == 1])
# Get individuals who had Confirmed_HI == 1 in that first year
first_year_individuals <- unique(filtered_data$Code[
filtered_data$Confirmed_HI == 1 & filtered_data$Year == first_year
])
# Assign yes/no based on that
ILV_all$Demons_HI_forage <- ifelse(ILV_all$Alias %in% first_year_individuals, "yes", "no")
# Create acquisition data
# Step 1: Filter filtered_data for confirmed HI behavior after first date
hi_data <- filtered_data[filtered_data$Confirmed_HI == 1 & filtered_data$Year != first_year, ]
# Step 2: Get the first year each Alias showed the behavior
first_hi_year <- aggregate(Year ~ Code, data = hi_data, FUN = min)
# Step 3: Create a new column for order of acquisition
first_hi_year$HI_Order_acquisition <- as.numeric(first_hi_year$Year)
# Step 4: Merge this info back into ILV_all
ILV_all <- merge(ILV_all, first_hi_year[, c("Code", "HI_Order_acquisition")],
by.x = "Alias", by.y = "Code", all.x = TRUE)
# Step 5: Replace NA with 0 for individuals who had the behavior in 1995
ILV_all$HI_Order_acquisition[ILV_all$Demons_HI_forage == "yes"] <- 0
# Change individuals who didn't require behavior to t_end +1
ILV_all$time <- ifelse(is.na(ILV_all$HI_Order_acquisition),
max(na.omit(ILV_all$HI_Order_acquisition)) + 1,
ILV_all$HI_Order_acquisition)
# Get unique years excluding 0
years <- sort(unique(ILV_all$time[ILV_all$time != 0]))
# Create a mapping: year â†’ index
year_map <- setNames(seq_along(years), years)
# Replace years with mapped values, keep 0 as 0
ILV_all$time <- ifelse(ILV_all$time == 0, 0, year_map[as.character(ILV_all$time)])
# Add end time
ILV_all$t_end <- max(na.omit(ILV_all$time))
# Edit the other needed columns
ILV_all$id <- ILV_all$Alias
ILV_all$trial <- 1
# Get rid of other columns
event_data <- ILV_all[, c("trial", "id", "time", "t_end")]
View(event_data)
ILV_all$Sex <- ifelse(ILV_all$Sex == "Female", 1, 0)
ILV_all$BirthYear <- as.numeric(ILV_all$BirthYear)
ILV_all$BirthYear <- ifelse(is.na(ILV_all$BirthYear), 1985, ILV_all$BirthYear)
# Constant ILVs
ILV_c <- data.frame(id = ILV_all$Alias,
sex = ILV_all$Sex)
# Time varying ILVs
ILV_tv <- data.frame(
trial = 1,
id = rep(ILV_all$Alias, each = 20),
time = rep(1995:2014, times = length(ILV_all$Alias)),
age = rep(1995:2014, times = length(ILV_all$Alias)) -
rep(ILV_all$BirthYear, each = 20)
)
# Change age to age groups
ILV_tv$age_group <- ifelse(ILV_tv$age >= 10, "adult",
ifelse(ILV_tv$age > 4, "juvenile", "calf"))
ILV_tv <- ILV_tv[, -4]
# Separate HI Behaviors to create weighted HI prop variable
#' BG = Beg: F, G, H
#' SD = Scavenge and Depredation: A, B, C, D, E
#' FG = Fixed Gear Interaction: P
# Change the code using ifelse statements
filtered_data <- subset(filtered_data, Code %in% unique(edge_list$focal))
filtered_data_list <- split(filtered_data, filtered_data$Year)
subset_HI <- function(aux_data) {
for (i in seq_along(aux_data)) {
aux_data[[i]]$DiffHI <- ifelse(aux_data[[i]]$ConfHI %in% c("F", "G", "H"), "BG",
ifelse(aux_data[[i]]$ConfHI %in% c("A", "B", "C", "D", "E"), "SD",
ifelse(aux_data[[i]]$ConfHI %in% c("P"), "FG", "None")))
}
return(aux_data)  # Return the modified list of data frames
}
aux <- subset_HI(filtered_data_list)
# Categorize DiffHI to IDs
diff_raw <- function(aux_data) {
rawHI_diff <- lapply(aux_data, function(df) {
table_df <- as.data.frame(table(df$Code, df$DiffHI))
colnames(table_df) <- c("Code", "DiffHI", "Freq")
return(table_df)
})}
rawHI_diff <- diff_raw(aux)
View(rawHI_diff)
View(rawHI_diff[["1995"]])
# Categorize ID to Sightings
ID_sight <- function(aux_data) {
IDbehav <- lapply(aux_data, function(df) {
data <- as.data.frame(table(df$Code))
colnames(data) <- c("Code", "Sightings")
# Order data
order_rows <- rownames(nxn[[1]])
# Now reorder the dataframe
data <- data %>%
arrange(match(Code, order_rows))
})
return(IDbehav)
}
IDbehav <- ID_sight(aux)
if(!require(tidyr)){install.packages('tidyr'); library(tidyr)}
if(!require(abind)){install.packages('abind'); library(abind)} # array
if(!require(STbayes)){install.packages('STbayes'); library(STbayes)}
if(!require(ggplot2)){install.packages('ggplot2'); library(ggplot2)}
if(!require(dplyr)){install.packages('dplyr'); library(dplyr)}
if(!require(posterior)){install.packages('posterior'); library(posterior)}
## Creating networks
if(!require(asnipe)){install.packages('asnipe'); library(asnipe)} # get_group_by_individual
if(!require(sf)){install.packages('sf'); library(sf)} # Convert degrees to meters
if(!require(sp)){install.packages('sp'); library(sp)} # Convert degrees to meters
if(!require(adehabitatHR)){install.packages('adehabitatHR'); library(adehabitatHR)} # Caluculate MCPs and Kernel density
if(!require(kinship2)){install.packages('kinship2'); library(kinship2)} # genetic relatedness
if(!require(doParallel)){install.packages('doParallel'); library(doParallel)} # for faster computing
# Categorize ID to Sightings
ID_sight <- function(aux_data) {
IDbehav <- lapply(aux_data, function(df) {
data <- as.data.frame(table(df$Code))
colnames(data) <- c("Code", "Sightings")
# Order data
order_rows <- rownames(nxn[[1]])
# Now reorder the dataframe
data <- data %>%
arrange(match(Code, order_rows))
})
return(IDbehav)
}
IDbehav <- ID_sight(aux)
View(IDbehav)
View(IDbehav[["1995"]])
i=1
df <- IDbehav[[i]]
View(df)
View(IDbehav)
View(IDbehav[["1995"]])
unlist(rawHI_diff)
i=1
IDbehav_HI <- IDbehav
# Categorize ID to Sightings
ID_sight <- function(aux_data) {
IDbehav <- lapply(aux_data, function(df) {
data <- as.data.frame(table(df$Code))
colnames(data) <- c("Code", "Sightings")
# Order data
order_rows <- rownames(nxn[[1]])
# Now reorder the dataframe
data <- data %>%
arrange(match(Code, order_rows))
})
return(IDbehav)
}
IDbehav <- ID_sight(aux)
# Create a frequency count for each HI behavior
get_IDHI <- function(HI, IDbehav_data, rawHI_diff_data) {
lapply(seq_along(IDbehav_data), function(i) {
df <- IDbehav_data[[i]]
HI_freq <- rawHI_diff_data[[i]]$Freq[rawHI_diff_data[[i]]$DiffHI == HI]
df$Behav <- HI_freq[match(df$Code, rawHI_diff_data[[i]]$Code)]
colnames(df) <- c("Code", "Sightings", "Behav")
return(df)
})
}
IDbehav_HI <- get_IDHI(c("BG", "FG", "SD"), IDbehav, rawHI_diff)
IDbehav <- IDbehav_HI
i=1
df <- IDbehav[[i]]
# Combine list of data frames into one big data frame with a year column
combined_df <- do.call(rbind, lapply(seq_along(rawHI_diff), function(i) {
df <- rawHI_diff[[i]]      # Take the i-th data frame
df$year <- i               # Add a column for the year
df                         # Return modified data frame
}))
View(combined_df)
year_count <- aggregate(DiffHI ~ Code, data = combined_df[combined_df$DiffHI > 0, ], FUN = length)
df <- IDbehav[[i]]
# Combine list of data frames into one big data frame with a year column
combined_df <- do.call(rbind, lapply(seq_along(rawHI_diff), function(i) {
df <- rawHI_diff[[i]]
df$year <- i
df
}))
combined_df$DiffHI <- as.numeric(as.character(combined_df$DiffHI))
# Combine list of data frames into one big data frame with a year column
combined_df <- do.call(rbind, lapply(seq_along(rawHI_diff), function(i) {
df <- rawHI_diff[[i]]
df$year <- i
df
}))
View(combined_df)
year_count <- aggregate(Freq ~ Code, data = combined_df[combined_df$Freq > 0, ], FUN = length)
year_count
View(df)
