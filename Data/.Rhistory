if(!require(devtools)){install.packages('devtools'); library(devtools)} # To load NBDA
if(!require(asnipe)){install.packages('asnipe'); library(asnipe)} # get_group_by_individual
if(!require(sf)){install.packages('sf'); library(sf)} # Convert degrees to meters
if(!require(sp)){install.packages('sp'); library(sp)} # Convert degrees to meters
if(!require(adehabitatHR)){install.packages('adehabitatHR'); library(adehabitatHR)} # Caluculate MCPs and Kernel density
if(!require(kinship2)){install.packages('kinship2'); library(kinship2)} # genetic relatedness
setwd("../../NBDA")
load_all()
# all networks available under https://datadryad.org/review?doi=doi:10.5061/dryad.sc26m6c.
setwd("../Data") # set working directory
setwd("C:/Users/bankh/My_Repos/NBDA_SBdolphins/Code")
# all networks available under https://datadryad.org/review?doi=doi:10.5061/dryad.sc26m6c.
setwd("../Data") # set working directory
data <- read.csv("orig_data.csv")
GPS <- data[, c("Code", "StartLon", "StartLat")]
colnames(GPS) <- c("id_individual", "longitude", "latitude")
# extract ID names from GPS file
IDs <- sort(as.vector(unique(GPS[,"id_individual"])))
# Vertical network -----------------------------------------
## Find the demographics of the population
ILV_pat <- read.csv("Paternity_data.csv")
## Subset paternity data
ILV_pat <- data.frame(Code = ILV_pat$Alias,
Mom = ILV_pat$Mom)
SRI_vert_all <- vert.func(ILV_pat)
source("../Code/functions.R") # nxn
# Vertical network -----------------------------------------
## Find the demographics of the population
ILV_pat <- read.csv("Paternity_data.csv")
## Subset paternity data
ILV_pat <- data.frame(Code = ILV_pat$Alias,
Mom = ILV_pat$Mom)
SRI_vert_all <- vert.func(ILV_pat)
# Horizontal network -----------------------------------------
orig_data <- read.csv("orig_data.csv") # original data
orig_data <- subset(orig_data, Code %in% ILV_pat$Code)
## Group each individual by date and sighting
group_data <- orig_data[,c("Date","Sighting","Code","Year")]
group_data$Group <- cumsum(!duplicated(group_data[1:2])) # Create sequential group # by date
group_data <- group_data[,3:5] # Subset ID and group #
## Gambit of the group index
gbi <- get_group_by_individual(group_data[,c("Code", "Group")], data_format = "individuals")
## Create association matrix
nxn <- as.matrix(SRI.func(gbi))
# Order data
id_order <- rownames(SRI_vert_all)
nxn_ordered <- nxn[id_order, id_order]
# Get rid of vertical data
SRI_hor_no_vert_all <- ifelse(SRI_vert_all == 1, 0, nxn_ordered)
# Save nxn
write.csv(SRI_hor_no_vert_all, "SRI_hor_no_vert_all.csv")
# Save vert
write.csv(SRI_vert_all, "SRI_vert_all.csv")
# Ecological network -----------------------------------------
# Transform coordinate data into a Spatial Points Dataframe in km
ids <- orig_data$Code
coordinates <- orig_data[, c("StartLon", "StartLat")]
# Create a SpatialPointsDataFrame with coordinates
coords_sp <- SpatialPointsDataFrame(coords = coordinates, data = data.frame(id = ids))
# Set CRS to WGS84
proj4string(coords_sp) <- CRS("+proj=longlat +datum=WGS84")
# Transform to a UTM CRS that uses km as the unit
dolph.sp <- spTransform(coords_sp, CRS("+proj=utm +zone=17 +datum=WGS84 +units=m +no_defs"))
# Use the calculated extent in kernelUD
kernel <- kernelUD(dolph.sp, h = 1000)
# Calculate Dyadic HRO Matrix: HRO = (Rij/Ri) * (Rij/Rj)
kov <- kerneloverlaphr(kernel, method = "HR", lev = 95)
# Order data
order_rows <- rownames(nxn)
order_cols <- colnames(nxn)
# Apply the order to each matrix in the list
ecol_all <- kov[order_rows, order_cols]
# Save eco dat
write.csv(ecol_all, "ecol_all.csv")
# Read relatedness network -----------------------------------------
ILV_pat <- read.csv("Paternity_data.csv")
# Order data
order_rows <- rownames(nxn)
order_cols <- colnames(nxn)
# Reorder rows in 'ILV' based on 'order_rows'
ILV <- ILV_pat[ILV_pat$Alias %in% order_rows, ]
ILV <- ILV[match(order_rows, ILV$Alias), ]
# Subset paternity data
pedigree_df <- data.frame(Alias = ILV$Alias,
Mom = ILV$Mom,
Dad = ILV$Dad,
Sex = ILV$Sex)
# Fix dad data
pedigree_df$Dad <- ifelse(pedigree_df$Dad == "na", NA, pedigree_df$Dad)
pedigree_df$Dad <- ifelse(pedigree_df$Dad == "FB26 or FB66", "FB26", pedigree_df$Dad)
pedigree_df$Dad <- ifelse(pedigree_df$Dad == "FB76 or FB38", "FB76", pedigree_df$Dad)
# Fix sex so that probable is assigned
pedigree_df$Sex <- ifelse(ILV$Sex == "Probable Female", "Female",
ifelse(ILV$Sex == "Probable Male", "Male", ILV$Sex))
# Make sex numeric
pedigree_df$Sex <- ifelse(pedigree_df$Sex == "Female", 2,
ifelse(pedigree_df$Sex == "Male", 1, NA))
# Fix sex so that probable is assigned
pedigree_df$Sex <- ifelse(ILV$Sex == "Probable Female", "Female",
ifelse(ILV$Sex == "Probable Male", "Male", ILV$Sex))
# Make sex numeric
pedigree_df$Sex <- ifelse(pedigree_df$Sex == "Female", 2,
ifelse(pedigree_df$Sex == "Male", 1, NA))
# Limit data to non-missing paternity IDs
pedigree_subset <- pedigree_df[!is.na(pedigree_df$Mom) | !is.na(pedigree_df$Dad), ]
# Reset row names to be sequential
row.names(pedigree_subset) <- NULL
# Make id numeric
## Moms
pedigree_df$ID <- rownames(pedigree_df)
for (i in 1:nrow(pedigree_df)) {
pedigree_df$Mom <- ifelse(pedigree_df$Mom %in% pedigree_df$Alias[i],
pedigree_df$ID[i], pedigree_df$Mom)
}
## Dads
for (i in 1:nrow(pedigree_df)) {
pedigree_df$Dad <- ifelse(pedigree_df$Dad %in% pedigree_df$Alias[i],
pedigree_df$ID[i], pedigree_df$Dad)
}
# Only take the ids that aren't found in the 117 list
missing_moms<- subset(pedigree_df, nchar(Mom) > 3)
missing_dads<- subset(pedigree_df, nchar(Dad) > 3)
# Create the sequence of numbers starting from 118
number_mom <- data.frame(Mom = unique(missing_moms$Mom),
ID = c((nrow(pedigree_df) + 1):(nrow(pedigree_df) + length(unique(missing_moms$Mom)))))
# Fill in numbers
for (i in 1:nrow(missing_moms)) {
missing_moms$Mom <- ifelse(missing_moms$Mom %in% number_mom$Mom[i],
number_mom$ID[i],
missing_moms$Mom)
}
# Make ID numeric
missing_moms$Mom <- as.numeric(missing_moms$Mom)
# Do the same thing with dads
number_dad <- data.frame(Dad = unique(missing_dads$Dad),
ID = c((max(missing_moms$Mom) + 1):(max(missing_moms$Mom) + length(unique(missing_dads$Dad)))))
for (i in 1:nrow(missing_dads)) {
missing_dads$Dad <- ifelse(missing_dads$Dad %in% number_dad$Dad[i],
number_dad$ID[i],
missing_dads$Dad)
}
# Make ID numeric
missing_dads$Dad <- as.numeric(missing_dads$Dad)
# Fill in the rest of the NAs with random numbers
## Moms
missing_moms_match <- subset(pedigree_df, nchar(Mom) > 3)
matching_indices <- match(pedigree_df$Mom, missing_moms_match$Mom)
pedigree_df$Mom <- ifelse(!is.na(matching_indices), missing_moms$Mom[matching_indices], pedigree_df$Mom)
## Dads
missing_dads_match<- subset(pedigree_df, nchar(Dad) > 3)
matching_indices <- match(pedigree_df$Dad, missing_dads_match$Dad)
pedigree_df$Dad <- ifelse(!is.na(matching_indices), missing_dads$Dad[matching_indices], pedigree_df$Dad)
## Now create data for function
pedigree_data <- data.frame(id = as.numeric(pedigree_df$ID),
mom = as.numeric(pedigree_df$Mom),
dad = as.numeric(pedigree_df$Dad),
sex = pedigree_df$Sex)
# Assuming your dataframe is named pedigree_data
pedigree_data$dad[is.na(pedigree_data$dad)] <- 0  # Replace NA with 0 or another appropriate code
pedigree_data$mom[is.na(pedigree_data$mom)] <- 0  # Replace NA with 0 or another appropriate code
# Add Fake Fathers
for (i in which(pedigree_data$mom > 0 & pedigree_data$dad == 0)) {
pedigree_data$dad[i] <- i + max(pedigree_data$dad)
}
# Create fake individuals
fake_ids <- (nrow(pedigree_df) + 1):(max(pedigree_data$dad) + 1)
fake <- data.frame(id = fake_ids,
mom = rep(0, length(fake_ids)),
dad = rep(0, length(fake_ids)),
sex = rep(3, length(fake_ids)))
pedigree_data <- rbind(pedigree_data, fake)
# Change errors
pedigree_data$sex[pedigree_data$id %in% c(139:270)] <- 1
pedigree_data$sex[pedigree_data$id %in% c(118:138)] <- 2
# For limited data
pedigree_data$sex[pedigree_data$id %in% c(94:112, 117:nrow(pedigree_data))] <- 1
pedigree_data$sex[pedigree_data$id %in% c(58:93)] <- 2
# Create GR matrix
ped <- pedigree(id = pedigree_data$id,
dadid = pedigree_data$dad,
momid = pedigree_data$mom,
sex = pedigree_data$sex)
# Read ILVs
ILV_all <- read.csv("ILV_dem.csv", header=TRUE, sep=",")
ILV_all <- ILV_all[, c("Alias", "HI_Indiv", "Mom")]
# Read orig_data
orig_data <- read.csv("orig_data.csv")
orig_data$Confirmed_HI <- ifelse(orig_data$ConfHI != "0", 1, 0)
# Create demonstrator column
ILV_all$Demons_HI_forage <- ifelse(
ILV_all$Alias %in% unique(orig_data$Code[orig_data$Confirmed_HI == 1 & orig_data$Year == 1995]),
"yes",
"no"
)
# Create acquisition data
# Step 1: Filter orig_data for confirmed HI behavior after 1995
hi_data <- orig_data[orig_data$Confirmed_HI == 1 & orig_data$Year > 1995, ]
# Step 2: Get the first year each Alias showed the behavior
first_hi_year <- aggregate(Year ~ Code, data = hi_data, FUN = min)
# Step 3: Create a new column for order of acquisition
first_hi_year$HI_Order_acquisition <- first_hi_year$Year - 1995
# Step 4: Merge this info back into ILV_all
ILV_all <- merge(ILV_all, first_hi_year[, c("Code", "HI_Order_acquisition")],
by.x = "Alias", by.y = "Code", all.x = TRUE)
# Step 5: Replace NA with 0 for individuals who had the behavior in 1995
ILV_all$HI_Order_acquisition[ILV_all$Demons_HI_forage == "yes"] <- 0
# Extract Confirmed_HI (learners and demonstrators)
Confirmed_HI <- subset(ILV_all, subset = ILV_all$HI_Indiv == 1)
Confirmed_HI <- Confirmed_HI[order(Confirmed_HI$HI_Order_acquisition),]
# get ID codes of all spongers
HI_all <- Confirmed_HI$Alias
# extract IDs of all spongers that are treated as learners
HI_learners <- as.vector(subset(Confirmed_HI$Alias, subset=Confirmed_HI$Demons_HI_forage=="no"))
# extract IDs of all spongers treated as demonstrators
HI_demons <- as.vector(subset(Confirmed_HI$Alias, subset=Confirmed_HI$Demons_HI_forage=="yes"))
# extract order of acquisition
order <- NULL # create an object to store the vector of acquistion
for (i in 1:length(HI_learners)){ # for each sponger, extract the position in the networks and ILV data frame
order[i] <- which(IDs==HI_learners[i])
}
order <- as.vector(order)
OAc <- order
# extract positions of demonstrators
demons <- NULL # create an object to store the vector of acquistion
for (i in 1:length(HI_demons)){ # for each sponger demonstrator, extract the position in the networks and ILV data frame
demons[i] <- which(IDs==HI_demons[i])
}
# contains positions of all sponger demonstrators
demons <- as.vector(demons)
# create vector of length(IDs) with 0 for non-demonstrators and 1 for demonstrators
demons_vector <- c(rep(0,length(IDs)))
for (i in demons){
demons_vector[i] <- 1
}
n.assMatrix <- 4 # number of matrices
assMatrix.B <- array(data = c(SRI_vert_all, SRI_hor_no_vert_all, ecol,
#relate
), dim=c(nrow(SRI_vert_all), ncol(SRI_vert_all), n.assMatrix)) # create an array with the four matrices
assMatrix.B <- array(data = c(SRI_vert_all, SRI_hor_no_vert_all, ecol_all,
#relate
), dim=c(nrow(SRI_vert_all), ncol(SRI_vert_all), n.assMatrix)) # create an array with the four matrices
assMatrix.B <- array(data = c(SRI_vert_all, SRI_hor_no_vert_all, ecol_all
#, relate
), dim=c(nrow(SRI_vert_all), ncol(SRI_vert_all), n.assMatrix)) # create an array with the four matrices
label <- "HIC"
View(Confirmed_HI)
# extract the Confirmed_HI learners with no maternity data available
HI_filter <- subset(Confirmed_HI, subset=Confirmed_HI$Demons_HI_forage=="no")
HI_filter2 <- sort(subset(HI_filter$id_individual, subset=HI_filter$Mom=NA))
HI_filter2 <- sort(subset(HI_filter$id_individual, subset=is.na(HI_filter$Mom)))
vec <- NULL
for (i in 1:length(HI_filter2)){
a <- which(IDs==HI_filter2[i])
vec[i] <- a
} # get position of spongers with no maternity data
filter <- paste0(label,"_", vec)
# create NBDA Data Object
nbdaDataHI.C <- nbdaData(label=label, assMatrix=assMatrix.B, orderAcq=OAc,asocialTreatment="constant", demons = demons_vector) # creates OADA object
