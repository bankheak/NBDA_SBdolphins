orig_data$Confirmed_HI <- ifelse(orig_data$ConfHI != "0", 1, 0)
orig_data$Date <- as.Date(as.character(orig_data$Date), format="%Y-%m-%d")
# Filter data to include individuals that were seen in all time periods
all_years <- sort(unique(orig_data$Year))
filtered_data <- orig_data[orig_data$Code %in% codes_all_years, ]
codes_all_years <- names(which(rowSums(table(orig_data$Code, orig_data$Year) > 0) == length(all_years)))
filtered_data <- orig_data[orig_data$Code %in% codes_all_years, ]
Codes <- unique(filtered_data$Code)
ILV_all <- subset(ILV_all, Alias %in% Codes)
# Read ILVs
ILV_all <- read.csv("ILV_dem.csv", header=TRUE, sep=",")
ILV_all <- ILV_all[, c("Alias", "HI_Indiv", "Mom", "Sex", "BirthYear")]
# Read orig_data
orig_data <- read.csv("orig_data.csv")
orig_data <- subset(orig_data, Code %in% ILV_all$Alias)
orig_data$Confirmed_HI <- ifelse(orig_data$ConfHI != "0", 1, 0)
orig_data$Date <- as.Date(as.character(orig_data$Date), format="%Y-%m-%d")
# Subset data to first acquisition event
first_idx <- which(orig_data$Confirmed_HI == 1)[1]
orig_data <- orig_data[first_idx:nrow(orig_data), ]
# Filter data to include individuals that were seen in all time periods
all_years <- sort(unique(orig_data$Year))
codes_all_years <- names(which(rowSums(table(orig_data$Code, orig_data$Year) > 0) == length(all_years)))
filtered_data <- orig_data[orig_data$Code %in% codes_all_years, ]
Codes <- unique(filtered_data$Code)
ILV_all <- subset(ILV_all, Alias %in% Codes)
# Add order of acquisition data
# Create demonstrator column
ILV_all$Demons_HI_forage <- ifelse(
ILV_all$Alias %in% unique(orig_data$Code[orig_data$Confirmed_HI == 1 &
orig_data$Date == min(orig_data$Date)]),
"yes",
"no"
)
View(ILV_all)
write.csv(filtered_data, "filtered_data.csv")
# Add order of acquisition data
# Create demonstrator column
ILV_all$Demons_HI_forage <- ifelse(
ILV_all$Alias %in% unique(filtered_data$Code[filtered_data$Confirmed_HI == 1 &
filtered_data$Date == min(filtered_data$Date)]),
"yes",
"no"
)
View(ILV_all)
# Create acquisition data
# Step 1: Filter filtered_data for confirmed HI behavior after first date
hi_data <- filtered_data[filtered_data$Confirmed_HI == 1 & filtered_data$Date != min(filtered_data$Date), ]
# Step 2: Get the first year each Alias showed the behavior
first_hi_year <- aggregate(Date ~ Code, data = hi_data, FUN = min)
# Step 3: Create a new column for order of acquisition
first_hi_year$HI_Order_acquisition <- as.numeric(first_hi_year$Date - min(first_hi_year$Date))
# Step 4: Merge this info back into ILV_all
ILV_all <- merge(ILV_all, first_hi_year[, c("Code", "HI_Order_acquisition")],
by.x = "Alias", by.y = "Code", all.x = TRUE)
# Step 5: Replace NA with 0 for individuals who had the behavior in 1995
ILV_all$HI_Order_acquisition[ILV_all$Demons_HI_forage == "yes"] <- 0
View(ILV_all)
# Save data
write.csv(ILV_all, "ILV_all_subset.csv")
# Count sightings per Code per Year
code_counts <- table(filtered_data$Year, filtered_data$Code)
code_counts_df <- as.data.frame(code_counts)
names(code_counts_df) <- c("Year", "Code", "Freq")
# Find Codes that have at least 5 sightings in every year they appear
# Step 1: Get minimum sightings per Code across all years
min_counts <- aggregate(Freq ~ Code, data = code_counts_df, FUN = min)
# Step 2: Keep only Codes with minimum count >= 5
valid_codes <- min_counts[min_counts$Freq >= 5, "Code"]
# Find the demographics of the population
ILV_pat <- read.csv("Paternity_data.csv")
Codes <- unique(filtered_data$Code)
ILV_pat <- subset(ILV_pat, Alias %in% Codes)
# Subset paternity data
ILV_pat <- data.frame(Code = ILV_pat$Alias,
Mom = ILV_pat$Mom)
SRI_vert_all <- vert.func(ILV_pat)
source("../Code/functions.R") # nxn
SRI_vert_all <- vert.func(ILV_pat)
# Save vert
saveRDS(SRI_vert_all, "SRI_vert_all.RData")
# Group each individual by date and sighting
group_data <- filtered_data[,c("Date","Sighting","Code","Year", "ConfHI")]
group_data$Confirmed_HI <- ifelse(group_data$ConfHI != "0", 1, 0)
group_data$Group <- cumsum(!duplicated(group_data[1:2])) # Create sequential group # by date
group_data <- group_data[,c(1, 3, 4, 6, 7)] # Subset ID and group #
# Add date as a date
group_data$Date <- as.Date(as.character(group_data$Date), format="%Y-%m-%d")
View(group_data)
# Subset the data to include observations only from before acquisition
first_HI_index <- tapply(seq_len(nrow(group_data)), group_data$Code, function(idx) {
hi_rows <- idx[group_data$Confirmed_HI[idx] == 1]
if (length(hi_rows) > 0) hi_rows[1] else Inf  # Inf means no HI for that Code
})
first_HI_index
View(filtered_data)
View(ILV_all)
keep_rows <- mapply(function(idx, cutoff) {
idx[idx <= cutoff]
}, split(seq_len(nrow(group_data)), group_data$Code), first_HI_index)
# Flatten to a single vector of row indices
keep_rows <- unlist(keep_rows)
keep_rows
View(filtered_data)
# Subset the data to include observations only from before acquisition
# 1. Identify Codes to exclude
exclude_codes <- ILV_all$Alias[ILV_all$Demons_HI_forage == 1]
# 2. Compute first HI index for each Code (same as before)
first_HI_index <- tapply(seq_len(nrow(group_data)), group_data$Code, function(idx) {
hi_rows <- idx[group_data$Confirmed_HI[idx] == 1]
if (length(hi_rows) > 0) hi_rows[1] else Inf
})
# 3. Remove excluded Codes from the split
split_rows <- split(seq_len(nrow(group_data)), group_data$Code)
split_rows <- split_rows[!names(split_rows) %in% exclude_codes]
# 4. Keep rows up to first HI for remaining Codes
keep_rows <- mapply(function(idx, cutoff) {
idx[idx <= cutoff]
}, split_rows, first_HI_index[names(split_rows)])
# 5. Flatten and subset
keep_rows <- unlist(keep_rows)
# Subset the data
group_data <- group_data[keep_rows, ]
View(group_data)
# Group each individual by date and sighting
group_data <- filtered_data[,c("Date","Sighting","Code","Year", "ConfHI")]
group_data$Confirmed_HI <- ifelse(group_data$ConfHI != "0", 1, 0)
group_data$Group <- cumsum(!duplicated(group_data[1:2])) # Create sequential group # by date
group_data <- group_data[,c(1, 3, 4, 6, 7)] # Subset ID and group #
# Add date as a date
group_data$Date <- as.Date(as.character(group_data$Date), format="%Y-%m-%d")
View(group_data)
# Subset the data to include observations only from before acquisition
# 1. Identify Codes to exclude
exclude_codes <- ILV_all$Alias[ILV_all$Demons_HI_forage == 1]
exclude_codes
# Subset the data to include observations only from before acquisition
# 1. Identify Codes to exclude
exclude_codes <- ILV_all$Alias[ILV_all$Demons_HI_forage == "Yes"]
exclude_codes
ILV_all$Demons_HI_forage
# Subset the data to include observations only from before acquisition
# 1. Identify Codes to exclude
exclude_codes <- ILV_all$Alias[ILV_all$Demons_HI_forage == "yes"]
exclude_codes
# 2. Compute first HI index for each Code (same as before)
first_HI_index <- tapply(seq_len(nrow(group_data)), group_data$Code, function(idx) {
hi_rows <- idx[group_data$Confirmed_HI[idx] == 1]
if (length(hi_rows) > 0) hi_rows[1] else Inf
})
# 3. Remove excluded Codes from the split
split_rows <- split(seq_len(nrow(group_data)), group_data$Code)
split_rows <- split_rows[!names(split_rows) %in% exclude_codes]
# 4. Keep rows up to first HI for remaining Codes
keep_rows <- mapply(function(idx, cutoff) {
idx[idx <= cutoff]
}, split_rows, first_HI_index[names(split_rows)])
# 5. Flatten and subset
keep_rows <- unlist(keep_rows)
# Subset the data
group_data <- group_data[keep_rows, ]
View(group_data)
# Subset the data to include observations only from before acquisition
# 1. Identify Codes to exclude
exclude_codes <- ILV_all$Alias[ILV_all$Demons_HI_forage == 'yes']
# 2. Compute first HI index for each Code
first_HI_index <- tapply(seq_len(nrow(group_data)), group_data$Code, function(idx) {
hi_rows <- idx[group_data$Confirmed_HI[idx] == 1]
if (length(hi_rows) > 0) hi_rows[1] else Inf
})
# 3. Split rows by Code
split_rows <- split(seq_len(nrow(group_data)), group_data$Code)
# 4. For excluded Codes: keep all rows; for others: keep up to first HI
keep_rows <- mapply(function(idx, cutoff, code) {
if (code %in% exclude_codes) {
idx  # keep everything for excluded Codes
} else {
idx[idx <= cutoff]  # keep up to first HI for others
}
}, split_rows, first_HI_index[names(split_rows)], names(split_rows))
# 5. Flatten and subset
keep_rows <- unlist(keep_rows)
# Subset the data
group_data <- group_data[keep_rows, ]
# Group each individual by date and sighting
group_data <- filtered_data[,c("Date","Sighting","Code","Year", "ConfHI")]
group_data$Confirmed_HI <- ifelse(group_data$ConfHI != "0", 1, 0)
group_data$Group <- cumsum(!duplicated(group_data[1:2])) # Create sequential group # by date
group_data <- group_data[,c(1, 3, 4, 6, 7)] # Subset ID and group #
# Add date as a date
group_data$Date <- as.Date(as.character(group_data$Date), format="%Y-%m-%d")
# Subset the data to include observations only from before acquisition
# 1. Identify Codes to exclude
exclude_codes <- ILV_all$Alias[ILV_all$Demons_HI_forage == 'yes']
# 2. Compute first HI index for each Code
first_HI_index <- tapply(seq_len(nrow(group_data)), group_data$Code, function(idx) {
hi_rows <- idx[group_data$Confirmed_HI[idx] == 1]
if (length(hi_rows) > 0) hi_rows[1] else Inf
})
# 3. Split rows by Code
split_rows <- split(seq_len(nrow(group_data)), group_data$Code)
# 4. For excluded Codes: keep all rows; for others: keep up to first HI
keep_rows <- mapply(function(idx, cutoff, code) {
if (code %in% exclude_codes) {
idx  # keep everything for excluded Codes
} else {
idx[idx <= cutoff]  # keep up to first HI for others
}
}, split_rows, first_HI_index[names(split_rows)], names(split_rows))
# 5. Flatten and subset
keep_rows <- unlist(keep_rows)
# Subset the data
group_data <- group_data[keep_rows, ]
View(group_data)
unique(group_data$Code)
# Now create a list for each year
group_data_list <- split(group_data, group_data$Year)
# Calculate Gambit of the group
create_gbi <- function(list_years) {
gbi <- list()
for (i in seq_along(list_years)) {
# Gambit of the group index
gbi[[i]] <- get_group_by_individual(list_years[[i]][,c("Code", "Group")], data_format = "individuals")
}
return(gbi)
}
gbi <- create_gbi(group_data_list)
saveRDS(gbi, "gbi.RData")
# Create association matrix
create_nxn <- function(gbi) {
n.cores <- detectCores()
system.time({
registerDoParallel(n.cores)
nxn <- list()
for (i in seq_along(gbi)) {
nxn[[i]] <- as.matrix(SRI.func(gbi[[i]]))
}
# End parallel processing
stopImplicitCluster()
})
return(nxn)
}
nxn <- create_nxn(gbi)
# Order data
id_order <- rownames(SRI_vert_all)
nxn_ordered <- lapply(nxn, function(mat) mat[id_order, id_order])
View(nxn)
View(gbi)
unique(group_data$Code)
unique(group_data$Code[group_data$Year == 1995])
unique(group_data$Code[group_data$Year == 1996])
unique(group_data_list$Code[[1]])
unique(group_data_list[[1]]$Code)
unique(group_data_list[[2]]$Code)
unique(group_data_list[[3]]$Code)
# Read ILVs
ILV_all <- read.csv("ILV_dem.csv", header=TRUE, sep=",")
ILV_all <- ILV_all[, c("Alias", "HI_Indiv", "Mom", "Sex", "BirthYear")]
# Read orig_data
orig_data <- read.csv("orig_data.csv")
orig_data <- subset(orig_data, Code %in% ILV_all$Alias)
orig_data$Confirmed_HI <- ifelse(orig_data$ConfHI != "0", 1, 0)
orig_data$Date <- as.Date(as.character(orig_data$Date), format="%Y-%m-%d")
# Subset data to first acquisition event
first_idx <- which(orig_data$Confirmed_HI == 1)[1]
orig_data <- orig_data[first_idx:nrow(orig_data), ]
# Filter data to include individuals that were seen in all time periods
all_years <- sort(unique(orig_data$Year))
codes_all_years <- names(which(rowSums(table(orig_data$Code, orig_data$Year) > 0) == length(all_years)))
codes_all_years
# Filter data to include individuals that were seen in all time periods
years <- unique(orig_data$Year)
codes_in_all_years <- names(which(table(orig_data$Code, orig_data$Year) > 0))
codes_in_all_years
table(orig_data$Code, orig_data$Year)
which(table(orig_data$Code, orig_data$Year) > 0)
names(which(table(orig_data$Code, orig_data$Year) > 0))
# Filter data to include individuals that were seen in all time periods
tab <- table(orig_data$Code, orig_data$Year)
tab
codes_in_all_years <- rownames(tab)[rowSums(tab > 0) == ncol(tab)]
codes_in_all_years
# Filter data to include individuals that were seen in all time periods
tab <- table(orig_data$Code, orig_data$Year)
codes_in_all_years <- rownames(tab)[rowSums(tab > 5) == ncol(tab)]
codes_in_all_years
filtered_data <- orig_data[orig_data$Code %in% codes_in_all_years, ]
write.csv(filtered_data, "filtered_data.csv")
# Subset ILVs to include these filtered individuals
Codes <- unique(filtered_data$Code)
ILV_all <- subset(ILV_all, Alias %in% Codes)
# Add order of acquisition data
# Create demonstrator column
ILV_all$Demons_HI_forage <- ifelse(
ILV_all$Alias %in% unique(filtered_data$Code[filtered_data$Confirmed_HI == 1 &
filtered_data$Date == min(filtered_data$Date)]),
"yes",
"no"
)
# Create acquisition data
# Step 1: Filter filtered_data for confirmed HI behavior after first date
hi_data <- filtered_data[filtered_data$Confirmed_HI == 1 & filtered_data$Date != min(filtered_data$Date), ]
# Step 2: Get the first year each Alias showed the behavior
first_hi_year <- aggregate(Date ~ Code, data = hi_data, FUN = min)
# Step 3: Create a new column for order of acquisition
first_hi_year$HI_Order_acquisition <- as.numeric(first_hi_year$Date - min(first_hi_year$Date))
# Step 4: Merge this info back into ILV_all
ILV_all <- merge(ILV_all, first_hi_year[, c("Code", "HI_Order_acquisition")],
by.x = "Alias", by.y = "Code", all.x = TRUE)
# Step 5: Replace NA with 0 for individuals who had the behavior in 1995
ILV_all$HI_Order_acquisition[ILV_all$Demons_HI_forage == "yes"] <- 0
# Save data
write.csv(ILV_all, "ILV_all_subset.csv")
# Count sightings per Code per Year
code_counts <- table(filtered_data$Year, filtered_data$Code)
code_counts_df <- as.data.frame(code_counts)
names(code_counts_df) <- c("Year", "Code", "Freq")
# Find the demographics of the population
ILV_pat <- read.csv("Paternity_data.csv")
Codes <- unique(filtered_data$Code)
ILV_pat <- subset(ILV_pat, Alias %in% Codes)
# Subset paternity data
ILV_pat <- data.frame(Code = ILV_pat$Alias,
Mom = ILV_pat$Mom)
SRI_vert_all <- vert.func(ILV_pat)
# Save vert
saveRDS(SRI_vert_all, "SRI_vert_all.RData")
# Read in filtered data
filtered_data <- read.csv("filtered_data.csv")
# Add individual data
ILV_all <- read.csv("ILV_all_subset.csv")
# Read in vertical network
SRI_vert_all <- readRDS("SRI_vert_all.RData")
# Group each individual by date and sighting
group_data <- filtered_data[,c("Date","Sighting","Code","Year", "ConfHI")]
group_data$Confirmed_HI <- ifelse(group_data$ConfHI != "0", 1, 0)
group_data$Group <- cumsum(!duplicated(group_data[1:2])) # Create sequential group # by date
group_data <- group_data[,c(1, 3, 4, 6, 7)] # Subset ID and group #
# Add date as a date
group_data$Date <- as.Date(as.character(group_data$Date), format="%Y-%m-%d")
View(group_data)
# Subset the data to include observations only from before acquisition
# 1. Identify Codes to exclude
exclude_codes <- ILV_all$Alias[ILV_all$Demons_HI_forage == 'yes']
# 2. Compute first HI index for each Code
first_HI_index <- tapply(seq_len(nrow(group_data)), group_data$Code, function(idx) {
hi_rows <- idx[group_data$Confirmed_HI[idx] == 1]
if (length(hi_rows) > 0) hi_rows[1] else Inf
})
# 3. Split rows by Code
split_rows <- split(seq_len(nrow(group_data)), group_data$Code)
# 4. For excluded Codes: keep all rows; for others: keep up to first HI
keep_rows <- mapply(function(idx, cutoff, code) {
if (code %in% exclude_codes) {
idx  # keep everything for excluded Codes
} else {
idx[idx <= cutoff]  # keep up to first HI for others
}
}, split_rows, first_HI_index[names(split_rows)], names(split_rows))
# 5. Flatten and subset
keep_rows <- unlist(keep_rows)
# Subset the data
group_data <- group_data[keep_rows, ]
View(group_data)
unique(group_data$Code)
# Now create a list for each year
group_data_list <- split(group_data, group_data$Year)
# Calculate Gambit of the group
create_gbi <- function(list_years) {
gbi <- list()
for (i in seq_along(list_years)) {
# Gambit of the group index
gbi[[i]] <- get_group_by_individual(list_years[[i]][,c("Code", "Group")], data_format = "individuals")
}
return(gbi)
}
gbi <- create_gbi(group_data_list)
saveRDS(gbi, "gbi.RData")
# Create association matrix
create_nxn <- function(gbi) {
n.cores <- detectCores()
system.time({
registerDoParallel(n.cores)
nxn <- list()
for (i in seq_along(gbi)) {
nxn[[i]] <- as.matrix(SRI.func(gbi[[i]]))
}
# End parallel processing
stopImplicitCluster()
})
return(nxn)
}
nxn <- create_nxn(gbi)
View(nxn)
# Group each individual by date and sighting
group_data <- filtered_data[,c("Date","Sighting","Code","Year", "ConfHI")]
group_data$Confirmed_HI <- ifelse(group_data$ConfHI != "0", 1, 0)
group_data$Group <- cumsum(!duplicated(group_data[1:2])) # Create sequential group # by date
group_data <- group_data[,c(1, 3, 4, 6, 7)] # Subset ID and group #
# Add date as a date
group_data$Date <- as.Date(as.character(group_data$Date), format="%Y-%m-%d")
# Now create a list for each year
group_data_list <- split(group_data, group_data$Year)
# Calculate Gambit of the group
create_gbi <- function(list_years) {
gbi <- list()
for (i in seq_along(list_years)) {
# Gambit of the group index
gbi[[i]] <- get_group_by_individual(list_years[[i]][,c("Code", "Group")], data_format = "individuals")
}
return(gbi)
}
gbi <- create_gbi(group_data_list)
# Create association matrix
create_nxn <- function(gbi) {
n.cores <- detectCores()
system.time({
registerDoParallel(n.cores)
nxn <- list()
for (i in seq_along(gbi)) {
nxn[[i]] <- as.matrix(SRI.func(gbi[[i]]))
}
# End parallel processing
stopImplicitCluster()
})
return(nxn)
}
nxn <- create_nxn(gbi)
View(nxn)
# Subset the data to include observations only from before acquisition
# 1. Identify Codes to exclude
exclude_codes <- ILV_all$Alias[ILV_all$Demons_HI_forage == 'yes']
# 2. Compute first HI index for each Code
first_HI_index <- tapply(seq_len(nrow(group_data)), group_data$Code, function(idx) {
hi_rows <- idx[group_data$Confirmed_HI[idx] == 1]
if (length(hi_rows) > 0) hi_rows[1] else Inf
})
first_HI_index
# 3. Split rows by Code
split_rows <- split(seq_len(nrow(group_data)), group_data$Code)
split_rows
# 4. For excluded Codes: keep all rows; for others: keep up to first HI
keep_rows <- mapply(function(idx, cutoff, code) {
if (code %in% exclude_codes) {
idx  # keep everything for excluded Codes
} else {
idx[idx <= cutoff]  # keep up to first HI for others
}
}, split_rows, first_HI_index[names(split_rows)], names(split_rows))
# 5. Flatten and subset
keep_rows <- unlist(keep_rows)
keep_rows
first_HI_index
# Group each individual by date and sighting
group_data <- filtered_data[,c("Date","Sighting","Code","Year", "ConfHI")]
group_data$Confirmed_HI <- ifelse(group_data$ConfHI != "0", 1, 0)
group_data$Group <- cumsum(!duplicated(group_data[1:2])) # Create sequential group # by date
group_data <- group_data[,c(1, 3, 4, 6, 7)] # Subset ID and group #
# Add date as a date
group_data$Date <- as.Date(as.character(group_data$Date), format="%Y-%m-%d")
# Subset the data to include observations only from before acquisition
# 1. Identify Codes to exclude
exclude_codes <- ILV_all$Alias[ILV_all$Demons_HI_forage == 'yes']
# 2. Compute first HI index for each Code
first_HI_index <- tapply(seq_len(nrow(group_data)), group_data$Code, function(idx) {
hi_rows <- idx[group_data$Confirmed_HI[idx] == 1]
if (length(hi_rows) > 0) hi_rows[1] else Inf
})
first_HI_index
# 3. Split rows by Code
split_rows <- split(seq_len(nrow(group_data)), group_data$Code)
# 4. For excluded Codes: keep all rows
# For others: keep up to first HI, or all if no HI (cutoff = Inf)
keep_rows <- mapply(function(idx, cutoff, code) {
if (code %in% exclude_codes || is.infinite(cutoff)) {
idx  # keep everything for excluded Codes or codes with no HI
} else {
idx[idx <= cutoff]  # keep up to first HI for others
}
}, split_rows, first_HI_index[names(split_rows)], names(split_rows))
# 5. Flatten and subset
keep_rows <- unlist(keep_rows)
# Subset the data
group_data <- group_data[keep_rows, ]
# Now create a list for each year
group_data_list <- split(group_data, group_data$Year)
# Calculate Gambit of the group
create_gbi <- function(list_years) {
gbi <- list()
for (i in seq_along(list_years)) {
# Gambit of the group index
gbi[[i]] <- get_group_by_individual(list_years[[i]][,c("Code", "Group")], data_format = "individuals")
}
return(gbi)
}
gbi <- create_gbi(group_data_list)
# Create association matrix
create_nxn <- function(gbi) {
n.cores <- detectCores()
system.time({
registerDoParallel(n.cores)
nxn <- list()
for (i in seq_along(gbi)) {
nxn[[i]] <- as.matrix(SRI.func(gbi[[i]]))
}
# End parallel processing
stopImplicitCluster()
})
return(nxn)
}
nxn <- create_nxn(gbi)
View(nxn)
